{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import random\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=100 # different random seed for all-negative so that we pick diff attribute pairs.\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZAPPOS_ROOT = '/home/amrith/zappos-50k/'\n",
    "ZAPPOS_IMAGES_ROOT = '/home/amrith/zappos-50k/ut-zap50k-images-square'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{ZAPPOS_ROOT}/ut-zap50k-data/meta-data-bin.csv')\n",
    "df['HeelHeight.High.heel'] = df['HeelHeight.4in...4.3.4in'] + df['HeelHeight.5in...over']\n",
    "df['HeelHeight.Short.heel'] = df['HeelHeight.Flat'] + df['HeelHeight.Under.1in'] + df['HeelHeight.1in...1.3.4in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50025, 154)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CID', 'Category.Boots', 'Category.Sandals', 'Category.Shoes', 'Category.Slippers', 'Closure.Adjustable', 'Closure.Ankle.Strap', 'Closure.Ankle.Wrap', 'Closure.Belt', 'Closure.Buckle', 'Closure.Bungee', 'Closure.Button.Loop', 'Closure.Elastic.Gore', 'Closure.Hook.and.Loop', 'Closure.Lace.up', 'Closure.Monk.Strap', 'Closure.Pull.on', 'Closure.Sling.Back', 'Closure.Slip.On', 'Closure.Snap', 'Closure.Spat.Strap', 'Closure.T.Strap', 'Closure.Toggle', 'Closure.Zipper', 'Gender.Boys', 'Gender.Girls', 'Gender.Men', 'Gender.Women', 'HeelHeight.1in...1.3.4in', 'HeelHeight.2in...2.3.4in', 'HeelHeight.3in...3.3.4in', 'HeelHeight.4in...4.3.4in', 'HeelHeight.5in...over', 'HeelHeight.Flat', 'HeelHeight.High.heel', 'HeelHeight.Short.heel', 'HeelHeight.Under.1in', 'Insole.EVA', 'Insole.Gel', 'Insole.Hypoallergenic', 'Insole.Latex.Lined', 'Insole.Leather', 'Insole.Memory.Foam', 'Insole.Moisture.Wicking', 'Insole.Orthotic.Friendly', 'Insole.Padded', 'Insole.Polyurethane', 'Insole.Poron', 'Insole.Removable', 'Insole.Synthetic.Leather', 'Insole.Textile', 'Material.Acrylic', 'Material.Aluminum', 'Material.Cable.Knit', 'Material.Canvas', 'Material.Cashmere', 'Material.Chiffon', 'Material.Cordura', 'Material.Corduroy', 'Material.Cork', 'Material.Cotton', 'Material.Crochet', 'Material.Crocodile', 'Material.Deerskin', 'Material.Denim', 'Material.Distressed.Leather', 'Material.EVA', 'Material.Exotic', 'Material.Faux.Fur', 'Material.Faux.Leather', 'Material.Faux.Suede', 'Material.Felt', 'Material.Fleece', 'Material.Full.grain.leather', 'Material.Hair.Calf', 'Material.Hemp', 'Material.Horse.Hair', 'Material.Jacquard', 'Material.Jute', 'Material.Lace', 'Material.Lambskin', 'Material.Latex', 'Material.Leather', 'Material.Linen', 'Material.Lizard', 'Material.Mesh', 'Material.Microfiber', 'Material.Nappa', 'Material.Neoprene', 'Material.Nubuck', 'Material.Nylon', 'Material.Ostrich', 'Material.Patent.Leather', 'Material.Plastic', 'Material.Polyester', 'Material.Polyurethane', 'Material.Raffia', 'Material.Ripstop', 'Material.Rubber', 'Material.Satin', 'Material.Shearling', 'Material.Sheepskin', 'Material.Silk', 'Material.Snakeskin', 'Material.Steel', 'Material.Stingray', 'Material.Suede', 'Material.Synthetic', 'Material.Terry', 'Material.Tweed', 'Material.Velour', 'Material.Velvet', 'Material.Vinyl', 'Material.Wool', 'SubCategory.Ankle', 'SubCategory.Athletic', 'SubCategory.Boat.Shoes', 'SubCategory.Boot', 'SubCategory.Clogs.and.Mules', 'SubCategory.Crib.Shoes', 'SubCategory.Firstwalker', 'SubCategory.Flat', 'SubCategory.Flats', 'SubCategory.Heel', 'SubCategory.Heels', 'SubCategory.Knee.High', 'SubCategory.Loafers', 'SubCategory.Mid.Calf', 'SubCategory.Over.the.Knee', 'SubCategory.Oxfords', 'SubCategory.Prewalker', 'SubCategory.Prewalker.Boots', 'SubCategory.Slipper.Flats', 'SubCategory.Slipper.Heels', 'SubCategory.Sneakers.and.Athletic.Shoes', 'ToeStyle.Algonquin', 'ToeStyle.Almond', 'ToeStyle.Apron Toe', 'ToeStyle.Bicycle Toe', 'ToeStyle.Bump Toe', 'ToeStyle.Capped Toe', 'ToeStyle.Center Seam', 'ToeStyle.Closed Toe', 'ToeStyle.Medallion', 'ToeStyle.Moc Toe', 'ToeStyle.Open Toe', 'ToeStyle.Peep Toe', 'ToeStyle.Pointed Toe', 'ToeStyle.Round Toe', 'ToeStyle.Snip Toe', 'ToeStyle.Snub Toe', 'ToeStyle.Square Toe', 'ToeStyle.Wide Toe Box', 'ToeStyle.Wingtip']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9f68f1732757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zappos_attributes_ID_OOD_partition.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mID_ATTR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mOOD_ATTR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "# Attribute list\n",
    "import json\n",
    "partition = json.load(open('zappos_attributes_ID_OOD_partition.json', 'r'))\n",
    "ID_ATTR = partition['train']\n",
    "OOD_ATTR = partition['test']\n",
    "print(len(TRAIN_ATTR))\n",
    "print(len(VALTEST_ATTR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. logic to sample attribute list\n",
    "2. logic to check if attributes are from same category\n",
    "3. logic to sample images that are positive for the attribute pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_category(attrs):\n",
    "    return len(set([attr.lower().split(\".\")[0] for attr in attrs])) < len(attrs)\n",
    "    \n",
    "def sample_attrs(attributes_list, n_attrs=2):\n",
    "    return np.random.choice(attributes_list, n_attrs, replace=False)\n",
    "\n",
    "def get_all_positive_images(df, attrs):\n",
    "    return df[attrs].apply(sum, axis=1) == len(attrs)\n",
    "\n",
    "def get_all_negative_images(df, attrs):\n",
    "    return (1-df[attrs]).apply(sum, axis=1) == len(attrs)\n",
    "\n",
    "def sample_images(df, selected_images, n_samples):\n",
    "    return list(np.random.choice(df[selected_images][\"CID\"].values, n_samples, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CID_to_impath = {x.split(\"/\")[-1][:-4].replace(\".\", \"-\"):x for x in glob.glob(f\"{ZAPPOS_IMAGES_ROOT}/**/*.jpg\", recursive=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(\n",
    "        ATTR_LIST, N_SAMPLES, \n",
    "        POSITIVE_IMAGES_THRESHOLD, NEGATIVE_IMAGES_THRESHOLD,\n",
    "        N_SUPPORT, N_QUERY):\n",
    "    \n",
    "    # main logic for sampling\n",
    "    n_selected = 0\n",
    "    dataset = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    counter = 0\n",
    "    import time\n",
    "    st = time.time()\n",
    "    while n_selected < N_SAMPLES:\n",
    "        counter += 1\n",
    "        # get attributes\n",
    "        attrs = sample_attrs(ATTR_LIST)\n",
    "        print(attrs)\n",
    "        # if any pair of the sampled attributes are from the same category then reject\n",
    "        if is_same_category(attrs):\n",
    "            # print(\"Dropped -- same category\", attrs)\n",
    "            continue\n",
    "        # get images which satisfy the attributes\n",
    "        positive_images = get_all_positive_images(df, attrs)\n",
    "        negative_images = positive_images.apply(lambda x: not x)\n",
    "        assert all([(x != y) for x,y in zip(positive_images, negative_images)])\n",
    "        # if we want to enforce 0s for all attributes then we need to change the logic above\n",
    "        # to include get_all_negative_images(df, attrs)\n",
    "\n",
    "        # if the no of images that are positive for the chosen attributes is too less, then reject \n",
    "        if (sum(positive_images) < POSITIVE_IMAGES_THRESHOLD) or (sum(negative_images) < NEGATIVE_IMAGES_THRESHOLD) :\n",
    "            # print(\"Dropped -- didnt meet threshold\", attrs)\n",
    "            continue\n",
    "\n",
    "        positive = [CID_to_impath[z] for z in sample_images(df, positive_images, N_SUPPORT+N_QUERY)]\n",
    "        negative = [CID_to_impath[z] for z in sample_images(df, negative_images, N_SUPPORT+N_QUERY)]\n",
    "\n",
    "        dataset[n_selected][0]['support'] = negative[:N_SUPPORT]\n",
    "        dataset[n_selected][0]['query'] = negative[N_SUPPORT:]\n",
    "\n",
    "        dataset[n_selected][1]['support'] = positive[:N_SUPPORT]\n",
    "        dataset[n_selected][1]['query'] = positive[N_SUPPORT:]\n",
    "\n",
    "        dataset[n_selected][0]['attributes'] = \"!(\" + \";\".join([a for a in attrs]) + \")\"\n",
    "        dataset[n_selected][1]['attributes'] = \";\".join(attrs)\n",
    "\n",
    "\n",
    "        n_selected += 1\n",
    "        print(f'Selected {n_selected}/{counter} Time Elapsed {time.time()-st}')\n",
    "        \n",
    "    return dataset\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_IMAGES_THRESHOLD = 20\n",
    "NEGATIVE_IMAGES_THRESHOLD = 20\n",
    "N_SUPPORT = 10\n",
    "N_QUERY = 10\n",
    "N_SAMPLES_ID = 11 # (1000 ID TRAIN, 5000/5000: ID VAL/TEST)\n",
    "N_SAMPLES_OOD = 20 # (5000/5000: OD VAL/TEST)\n",
    "\n",
    "print(\"--\"*10, \"ID\", \"--\"*10)\n",
    "ID_dataset = sample_dataset(\n",
    "    ID_ATTR,\n",
    "    N_SAMPLES = N_SAMPLES_ID,\n",
    "    POSITIVE_IMAGES_THRESHOLD = POSITIVE_IMAGES_THRESHOLD,\n",
    "    NEGATIVE_IMAGES_THRESHOLD = NEGATIVE_IMAGES_THRESHOLD,\n",
    "    N_SUPPORT = N_SUPPORT,\n",
    "    N_QUERY = N_QUERY)\n",
    "\n",
    "print(\"--\"*10, \"OOD\", \"--\"*10)\n",
    "OOD_dataset = sample_dataset(\n",
    "    OOD_ATTR,\n",
    "    N_SAMPLES = N_SAMPLES_OOD,\n",
    "    POSITIVE_IMAGES_THRESHOLD = POSITIVE_IMAGES_THRESHOLD,\n",
    "    NEGATIVE_IMAGES_THRESHOLD = NEGATIVE_IMAGES_THRESHOLD,\n",
    "    N_SUPPORT = N_SUPPORT,\n",
    "    N_QUERY = N_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ID_dataset, \n",
    "          open(f'zappos-ID-alltrue_vs_anyfalse-nsamp{N_TRAIN_SAMPLES},{N_VAL_SAMPLES},{N_TEST_SAMPLES}-ns{N_SUPPORT}-nq{N_QUERY}.json', 'w'))\n",
    "\n",
    "json.dump(OOD_dataset, \n",
    "          open(f'zappos-OOD-alltrue_vs_anyfalse-nsamp{N_TRAIN_SAMPLES},{N_VAL_SAMPLES},{N_TEST_SAMPLES}-ns{N_SUPPORT}-nq{N_QUERY}.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
