{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_class(c):\n",
    "    '''\n",
    "    maps hexadecimal class value (string) to a decimal number\n",
    "    returns:\n",
    "    - 0 through 9 for classes representing respective numbers\n",
    "    - 10 through 35 for classes representing respective uppercase letters\n",
    "    - 36 through 61 for classes representing respective lowercase letters\n",
    "    '''\n",
    "    if c.isdigit() and int(c) < 40:\n",
    "        return (int(c) - 30)\n",
    "    elif int(c, 16) <= 90: # uppercase\n",
    "        return (int(c, 16) - 55)\n",
    "    else:\n",
    "        return (int(c, 16) - 61)\n",
    "\n",
    "def add_class_images(class_root_path, user_to_class_to_imagepath):\n",
    "    \"\"\"\n",
    "    class_root_path is root of class directory\n",
    "    user_to_class_to_imagepath: defaultdict(lambda: defaultdict(list))\n",
    "                                is a dictionary mapping user->class->imagepath\n",
    "\n",
    "    use .mit file's mapping information to add every example of this class to the correct user\n",
    "    \"\"\"\n",
    "\n",
    "    class_hex = os.path.basename(class_root_path)\n",
    "    class_label = relabel_class(class_hex)\n",
    "    print(f\"Reading class hex {class_hex}, char {chr(int(class_hex, 16))}\")\n",
    "            \n",
    "    for hsf_fname in os.listdir(class_root_path):\n",
    "        # read mit files which contain metadata\n",
    "        if 'mit' in hsf_fname:\n",
    "            with open(os.path.join(class_root_path, hsf_fname)) as f:\n",
    "                class_images_details = list(map(\n",
    "                    lambda x: x.strip().split(), f.readlines()))\n",
    "            \n",
    "            # drop first line of class_images_details, since it only contains count\n",
    "            count, class_images_details = int(class_images_details[0][0]), class_images_details[1:]\n",
    "\n",
    "            # iterate over class_images_details\n",
    "            for image_fname, user_info in class_images_details:\n",
    "                user_id = user_info.split(\"/\")[0]\n",
    "                \n",
    "                # add root directory and hsf directory to image_fname\n",
    "                full_image_path = os.path.join(\n",
    "                    class_root_path,\n",
    "                    hsf_fname.split(\".\")[0], # remove mit extension\n",
    "                    image_fname\n",
    "                ) \n",
    "\n",
    "                # add data to class/user dict\n",
    "                user_to_class_to_imagepath[user_id][class_label].append(full_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femnist_root = ''\n",
    "user_to_class_to_imagepath = defaultdict(lambda: defaultdict(list))\n",
    "classes_home = os.path.join(femnist_root, \"data/raw_data/by_class\")\n",
    "for class_name in sorted(os.listdir(classes_home)):\n",
    "    class_root_path = os.path.join(\n",
    "        classes_home,\n",
    "        class_name)\n",
    "    add_class_images(\n",
    "        class_root_path,\n",
    "        user_to_class_to_imagepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_to_class_to_imagepath.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_minimum = 2 # every class has to have at least this number of examples\n",
    "per_user_minimum = 2 # every user has to have at least this number of classes\n",
    "n_shot = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_numcl = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, cl_to_imagepath in user_to_class_to_imagepath.items():\n",
    "    for cl, pathlist in list(cl_to_imagepath.items()):\n",
    "        if len(pathlist) < per_class_minimum:\n",
    "            del cl_to_imagepath[cl]\n",
    "    user_to_numcl[user] = len(cl_to_imagepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(user_to_class_to_imagepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([val for val in user_to_numcl.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in user_to_numcl:\n",
    "    if user_to_numcl[user] < per_user_minimum:\n",
    "        del user_to_class_to_imagepath[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(user_to_class_to_imagepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=100)\n",
    "all_users = list(sorted(user_to_class_to_imagepath.keys()))\n",
    "# random.shuffle(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_class_to_sq_to_imagepath = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in all_users:\n",
    "    cl_list = sorted(user_to_class_to_imagepath[user].keys())\n",
    "#     chosen_classes = random.sample(cl_list, k=per_user_minimum)\n",
    "    for cl in cl_list:\n",
    "#         chosen_examples = random.sample(user_to_class_to_imagepath[user][cl], k=per_class_minimum)\n",
    "        chosen_examples = user_to_class_to_imagepath[user][cl]\n",
    "        random.shuffle(chosen_examples)\n",
    "        user_to_class_to_sq_to_imagepath[user][cl]['support'].extend(chosen_examples[:n_shot])\n",
    "        user_to_class_to_sq_to_imagepath[user][cl]['query'].extend(chosen_examples[n_shot:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_class_to_sq_to_imagepath['f0620_49']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = f'fixedsq_atleast{per_user_minimum}class{n_shot}shot{per_class_minimum - n_shot}query_split'\n",
    "os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 0.7, 0.85 # percentage of train, followed by percentage of test\n",
    "train_users = all_users[:int(len(user_to_class_to_imagepath) * cut_off[0])]\n",
    "val_users = all_users[int(len(user_to_class_to_imagepath) * cut_off[0]):int(len(user_to_class_to_imagepath) * cut_off[1])]\n",
    "test_users = all_users[int(len(user_to_class_to_imagepath) * cut_off[1]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_users))\n",
    "print(len(val_users))\n",
    "print(len(test_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{folder_name}/base.json\", 'w') as f:\n",
    "    json.dump({user: user_to_class_to_sq_to_imagepath[user] for user in train_users}, f)\n",
    "with open(f\"{folder_name}/val.json\", 'w') as f:\n",
    "    json.dump({user: user_to_class_to_sq_to_imagepath[user] for user in val_users}, f)\n",
    "with open(f\"{folder_name}/novel.json\", 'w') as f:\n",
    "    json.dump({user: user_to_class_to_sq_to_imagepath[user] for user in test_users}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_class_to_sq_to_imagepath[train_users[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the raw data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([len(cl_to_imagepath) for cl_to_imagepath in user_to_class_to_imagepath.values()])[:10]\n",
    "# the writers with the smallest number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, cl_to_imagepath in user_to_class_to_imagepath.items():\n",
    "    print(sorted([len(x) for x in cl_to_imagepath.values()])[-5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
