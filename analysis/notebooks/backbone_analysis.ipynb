{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import argparse\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pprint\n",
    "from tensorboardX import SummaryWriter\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numpy.linalg import svd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sys.path = ['..'] + sys.path\n",
    "from algorithm_trainer.models import gated_conv_net_original, resnet, resnet_2, resnet_12, conv64\n",
    "from algorithm_trainer.algorithm_trainer import Generic_adaptation_trainer, Classical_algorithm_trainer\n",
    "from algorithm_trainer.algorithms.algorithm import SVM, ProtoNet, Finetune, ProtoCosineNet\n",
    "from algorithm_trainer.utils import accuracy\n",
    "from data_layer.dataset_managers import MetaDataManager, ClassicalDataManager\n",
    "from analysis.objectives import var_reduction_disc, var_reduction_disc_perp, var_reduction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint):\n",
    "    print(f\"loading from {checkpoint}\")\n",
    "    model_dict = model.state_dict()\n",
    "    chkpt_state_dict = torch.load(checkpoint)\n",
    "    if 'model' in chkpt_state_dict:\n",
    "        chkpt_state_dict = chkpt_state_dict['model']\n",
    "    chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "    # remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "    for key in chkpt_state_dict_cpy.keys():\n",
    "        if 'module.' in key:\n",
    "            new_key = re.sub('module\\.', '',  key)\n",
    "            chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "    chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "    model_dict.update(chkpt_state_dict)\n",
    "    updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "    missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "    print(f\"Missed {len(missed_keys)} keys\")\n",
    "    model.load_state_dict(model_dict)\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "    model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit norm projection is  False\n",
      "loading from ../train_dir_2/metalfixsepoch_euc_MI_r12_n64_s3_q128_2/classical_resnet_105.pt\n",
      "Missed 0 keys\n",
      "n_way: 5, n_shot: 5, n_query: 15, batch_sz: 1\n",
      "Iteration: 150          \n",
      "train loss after: \t1.404\n",
      "test loss after: \t1.468\n",
      " \n",
      "train accu after: \t96.000\n",
      "test accu after: \t68.000\n",
      " \n",
      "Iteration: 300          \n",
      "train loss after: \t1.450\n",
      "test loss after: \t1.510\n",
      " \n",
      "train accu after: \t92.000\n",
      "test accu after: \t70.667\n",
      " \n",
      "Iteration: 450          \n",
      "train loss after: \t1.370\n",
      "test loss after: \t1.436\n",
      " \n",
      "train accu after: \t100.000\n",
      "test accu after: \t70.667\n",
      " \n",
      "                        \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss_trajectory': defaultdict(float,\n",
       "             {'loss': array([1.40548441]), 'accu': array([96.44799846])}),\n",
       " 'test_loss_after': defaultdict(float,\n",
       "             {'loss': 1.4597493722438812, 'accu': 76.97600182294846}),\n",
       " 'val_task_acc': '76.98 Â± 0.71 %'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 84\n",
    "batch_size = 1\n",
    "n_way = 5\n",
    "n_shot = 5\n",
    "n_query = 15\n",
    "n_episodes = 500\n",
    "dataset_path = '../data/filelists/miniImagenet/'\n",
    "chkpt = '../train_dir_2/metalfixsepoch_euc_MI_r12_n64_s3_q128_2/classical_resnet_105.pt'\n",
    "model = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model = load_model(model, chkpt)\n",
    "\n",
    "algorithm = ProtoNet(\n",
    "    model=model,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_way=n_way,\n",
    "    n_shot=n_shot,\n",
    "    n_query=n_query,\n",
    "    device='cuda')\n",
    "\n",
    "adaptation_trainer = Generic_adaptation_trainer(\n",
    "    algorithm=algorithm,\n",
    "    aux_objective=None,\n",
    "    outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    outer_optimizer=None, \n",
    "    writer=None,\n",
    "    log_interval=150,\n",
    "    model_type='resnet12'\n",
    ")\n",
    "\n",
    "val_file = os.path.join(dataset_path, 'novel.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=batch_size, n_episodes=n_episodes,\n",
    "    n_way=n_way, n_shot=n_shot, n_query=n_query)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, support_aug=False, query_aug=False)\n",
    "adaptation_trainer.run(meta_val_loader, meta_val_datamgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-d interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, parameters, split):\n",
    "    image_size = parameters['image_size']\n",
    "    batch_size = 1\n",
    "    n_way = parameters[split]['n_way']\n",
    "    n_shot = parameters[split]['n_shot']\n",
    "    n_query = parameters[split]['n_query']\n",
    "    n_episodes = 100\n",
    "    dataset_path = f\"../data/filelists/{dataset}\"\n",
    "    \n",
    "    algorithm = ProtoNet(\n",
    "        model=model,\n",
    "        inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "        n_way=n_way,\n",
    "        n_shot=n_shot,\n",
    "        n_query=n_query,\n",
    "        device='cuda')\n",
    "\n",
    "    adaptation_trainer = Generic_adaptation_trainer(\n",
    "        algorithm=algorithm,\n",
    "        aux_objective=None,\n",
    "        outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "        outer_optimizer=None, \n",
    "        writer=None,\n",
    "        log_interval=1500,\n",
    "        model_type='resnet12'\n",
    "    )\n",
    "\n",
    "    if split == 'train':\n",
    "        file = os.path.join(dataset_path, 'base.json')\n",
    "    else:\n",
    "        file = os.path.join(dataset_path, 'novel.json')\n",
    "    \n",
    "    meta_datamgr = MetaDataManager(\n",
    "        image_size, batch_size=batch_size, n_episodes=500,\n",
    "        n_way=n_way, n_shot=n_shot, n_query=n_query)\n",
    "    meta_loader = meta_datamgr.get_data_loader(file, support_aug=False, query_aug=False)\n",
    "    return adaptation_trainer.run(meta_loader, meta_datamgr)['test_loss_after']['loss']\n",
    "\n",
    "\n",
    "def moving_average(net1, net2, net, alpha=1):\n",
    "    for param, param1, param2 in zip(net.parameters(), net1.parameters(), net2.parameters()):\n",
    "        param.data = (1.0 - alpha) * param1.data + alpha * param2.data\n",
    "    return net\n",
    "\n",
    "\n",
    "def _check_bn(module, flag):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        flag[0] = True\n",
    "\n",
    "\n",
    "def check_bn(model):\n",
    "    flag = [False]\n",
    "    model.apply(lambda module: _check_bn(module, flag))\n",
    "    return flag[0]\n",
    "\n",
    "\n",
    "def reset_bn(module):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.running_mean = torch.zeros_like(module.running_mean)\n",
    "        module.running_var = torch.ones_like(module.running_var)\n",
    "\n",
    "\n",
    "def _get_momenta(module, momenta):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        momenta[module] = module.momentum\n",
    "\n",
    "\n",
    "def _set_momenta(module, momenta):\n",
    "    if issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.momentum = momenta[module]\n",
    "\n",
    "\n",
    "def bn_update(loader, model):\n",
    "    \"\"\"\n",
    "        BatchNorm buffers update (if any).\n",
    "        Performs 1 epochs to estimate buffers average using train dataset.\n",
    "        :param loader: train dataset loader for buffers average estimation.\n",
    "        :param model: model being update\n",
    "        :return: None\n",
    "    \"\"\"\n",
    "    if not check_bn(model):\n",
    "        return\n",
    "    model.train()\n",
    "    momenta = {}\n",
    "    model.apply(reset_bn)\n",
    "    model.apply(lambda module: _get_momenta(module, momenta))\n",
    "    n = 0\n",
    "    for input, _ in loader:\n",
    "        input = input.cuda()\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        b = input_var.data.size(0)\n",
    "\n",
    "        momentum = b / (n + b)\n",
    "        for module in momenta.keys():\n",
    "            module.momentum = momentum\n",
    "\n",
    "        model(input_var)\n",
    "        n += b\n",
    "\n",
    "    model.apply(lambda module: _set_momenta(module, momenta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(model_0, model_1, model, dataset, parameters, loader, eta=0.05, alpha_st=-0.2, alpha_end=1.2):\n",
    "\n",
    "      \n",
    "    metrics = defaultdict(list)\n",
    "    for alpha in np.arange(alpha_st, alpha_end, eta):\n",
    "        with torch.no_grad():\n",
    "            model = moving_average(model_0, model_1, model, eta)\n",
    "            bn_update(loader, model)\n",
    "            metrics['train'].append(evaluate(model, dataset, parameters, split='train'))\n",
    "            metrics['test'].append(evaluate(model, dataset, parameters, split='test'))\n",
    "            print(\"alpha\",  alpha, metrics['train'][-1], metrics['test'][-1])\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'image_size': 84,\n",
    "    'train': {\n",
    "        'n_way': 64,\n",
    "        'n_shot': 5,\n",
    "        'n_query': 5\n",
    "    },\n",
    "    'test': {\n",
    "        'n_way': 5,\n",
    "        'n_shot': 5,\n",
    "        'n_query': 15 \n",
    "    }\n",
    "}  \n",
    "dataset = 'miniImagenet'\n",
    "\n",
    "dataset_path = f\"../data/filelists/{dataset}\"\n",
    "file = os.path.join(dataset_path, 'base.json')    \n",
    "cl_datamgr = ClassicalDataManager(parameters['image_size'], batch_size=128)\n",
    "loader = cl_datamgr.get_data_loader(file, aug=False)\n",
    "\n",
    "\n",
    "chkpt = '../train_dir/metal_MI_r12_n60_s5_q5_euc/classical_resnet_020.pt'\n",
    "model_fixS = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model_fixS = load_model(model_fixS, chkpt)\n",
    "chkpt = '../train_dir/metal_MI_r12_n64_s3_q128_ML/classical_resnet_120.pt'\n",
    "model_meta = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model_meta = load_model(model_meta, chkpt)\n",
    "model = resnet_12.resnet12(avg_pool=True, drop_rate=0.1, dropblock_size=5, no_fc_layer=True, projection=False)\n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()\n",
    "\n",
    "metrics = plot_loss(model_fixS, model_meta, model, 'miniImagenet', parameters, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.plot(metrics['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_2.ResNet18(\n",
    "    num_classes=64,  \n",
    "    add_bias=False, \n",
    "    no_fc_layer=False,\n",
    "    classifier_type='linear'\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint = '../train_dir/classical_miniimagenet_dc_bn_with_rfc_var_ortho/classical_resnet_147.pt'\n",
    "print(f\"loading from {checkpoint}\")\n",
    "model_dict = model.state_dict()\n",
    "chkpt_state_dict = torch.load(checkpoint)\n",
    "if 'model' in chkpt_state_dict:\n",
    "    chkpt_state_dict = chkpt_state_dict['model']\n",
    "chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "# remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "for key in chkpt_state_dict_cpy.keys():\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(chkpt_state_dict)\n",
    "updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "print(f\"Updated {len(updated_keys)} keys using chkpt\")\n",
    "print(\"Following keys updated :\", \"\\n\".join(sorted(updated_keys)))\n",
    "missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed :\", \"\\n\".join(sorted(missed_keys)))\n",
    "model.load_state_dict(model_dict)\n",
    "        \n",
    "        \n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dc = resnet_2.ResNet18(\n",
    "    num_classes=64,  \n",
    "    no_fc_layer=False,\n",
    "    classifier_type='ortho-classifier'\n",
    ")\n",
    "\n",
    "\n",
    "checkpoint = '../train_dir/classical_miniimagenet_dc_bn_ldim/classical_resnet_137.pt'\n",
    "print(f\"loading from {checkpoint}\")\n",
    "model_dict = model_dc.state_dict()\n",
    "chkpt_state_dict = torch.load(checkpoint)\n",
    "if 'model' in chkpt_state_dict:\n",
    "    chkpt_state_dict = chkpt_state_dict['model']\n",
    "chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "# remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "for key in chkpt_state_dict_cpy.keys():\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(chkpt_state_dict)\n",
    "updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "print(f\"Updated {len(updated_keys)} keys using chkpt\")\n",
    "print(\"Following keys updated :\", \"\\n\".join(sorted(updated_keys)))\n",
    "missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed :\", \"\\n\".join(sorted(missed_keys)))\n",
    "model_dc.load_state_dict(model_dict)\n",
    "        \n",
    "        \n",
    "model_dc = torch.nn.DataParallel(model_dc, device_ids=range(torch.cuda.device_count()))\n",
    "model_dc.cuda()\n",
    "model_dc.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "train_file = os.path.join(dataset_path, 'base.json')\n",
    "classical_val_datamgr = ClassicalDataManager(image_size, batch_size=16)\n",
    "classical_val_loader = classical_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "classical_train_datamgr = ClassicalDataManager(image_size, batch_size=16)\n",
    "classical_train_loader = classical_val_datamgr.get_data_loader(train_file, aug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, dataloader):\n",
    "    iterator = tqdm(dataloader)\n",
    "    features = defaultdict(list)\n",
    "    for batch in iterator:\n",
    "        batch_x, batch_y = batch\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cpu().numpy()\n",
    "        features_x = model(batch_x, features_only=True)\n",
    "        for y in np.unique(batch_y):\n",
    "            features[y].append(features_x[batch_y==y].detach().cpu().numpy())\n",
    "    for key in features:\n",
    "        features[key] = np.concatenate(features[key], axis=0) \n",
    "        print(f\"Received {features[key].shape} for class {key}\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adhoc anmalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_features = get_features(model, classical_val_loader)\n",
    "train_features = get_features(model, classical_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_features_dc = get_features(model_dc, classical_val_loader)\n",
    "train_features_dc = get_features(model_dc, classical_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(64, 80):\n",
    "    A = val_features_dc[x] / np.linalg.norm(val_features_dc[x]+0.00001, axis=1)[:, None]\n",
    "    print(x, (A @ A.T).mean(), (A @ A.T).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, 64):\n",
    "    A = train_features_dc[x] / np.linalg.norm(train_features_dc[x]+0.00001, axis=1)[:, None]\n",
    "    print(x, (A @ A.T).mean(), (A @ A.T).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.cumsum(PCA().fit(val_features_dc[65]).explained_variance_ratio_) < 0.8) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.svd(val_features_dc[69])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = []\n",
    "for x in range(64, 80):\n",
    "    plt.plot(np.cumsum(PCA().fit(val_features_dc[x] / np.linalg.norm(val_features_dc[x], axis=1)[:, None]).explained_variance_ratio_[:10]), label='train', color='blue')\n",
    "    avg.append(sum(np.cumsum(PCA().fit(val_features_dc[x] / np.linalg.norm(val_features_dc[x], axis=1)[:, None]).explained_variance_ratio_) < 0.8) + 1)\n",
    "print(np.mean(avg))\n",
    "# for x in range(0, 64):\n",
    "#     plt.plot(np.cumsum(PCA().fit(train_features_dc[x]).explained_variance_ratio_[:10]), label='train_dc', color='green')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x, PCA().fit(train_features_dc[10]).components_[0] @ model_dc.module.fc.L.weight_v[x].detach().cpu().numpy()) for x in range(64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(pairwise_distances(\n",
    "    PCA().fit(val_features_dc[65]).components_,\n",
    "    PCA().fit(val_features_dc[66]).components_,\n",
    "    metric='cosine'\n",
    ")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(PCA().fit(val_features[71]).explained_variance_ratio_[:30]), label='val')\n",
    "plt.plot(np.cumsum(PCA().fit(train_features[40]).explained_variance_ratio_[:30]), label='train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking linear seperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = val_features_dc\n",
    "dim = feature_set[list(feature_set.keys())[0]].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset:    \n",
    "    def __init__(self, features):\n",
    "        self.features = np.concatenate([features[x] for x in features], axis=0)\n",
    "        self.target = np.repeat(np.arange(len(features)), features[list(features.keys())[0]].shape[0])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.target[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(feature_set)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "M = torch.nn.Linear(dim, len(feature_set))\n",
    "torch.nn.init.xavier_uniform_(M.weight)\n",
    "M = M.cuda()\n",
    "loss_layer = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(M.parameters(), lr=0.001)\n",
    "# train\n",
    "for epoch in range(1000):\n",
    "    for i, (batch_x, batch_y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.cuda()\n",
    "#         batch_x = batch_x / (torch.norm(batch_x, dim=1, p=2, keepdim=True) + 0.00001)\n",
    "        batch_y = batch_y.cuda()\n",
    "        logits = M(batch_x)\n",
    "        loss = loss_layer(logits, batch_y)\n",
    "        loss.backward()\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"epoch: {epoch} iter : {i} loss : {loss.item()}, accuracy: {accuracy(logits, batch_y) * 100.}\")\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu = []\n",
    "loss = []\n",
    "for i, (batch_x, batch_y) in enumerate(loader):\n",
    "    batch_x = batch_x.cuda()\n",
    "    batch_x = batch_x / (torch.norm(batch_x, dim=1, p=2, keepdim=True) + 0.00001)\n",
    "    batch_y = batch_y.cuda()\n",
    "    with torch.no_grad():\n",
    "        logits = M(batch_x)\n",
    "        loss.append(loss_layer(logits, batch_y).item())\n",
    "        accu.append(accuracy(logits, batch_y) * 100.)\n",
    "print(np.mean(accu), np.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensionality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = val_features_dc\n",
    "dim = feature_set[list(feature_set.keys())[0]].shape[1]\n",
    "n_classes = len(feature_set)\n",
    "low_dim = 20\n",
    "label_offset = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone, dim, low_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.backbone.eval()\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, low_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(low_dim, low_dim),\n",
    "            torch.nn.Linear(low_dim, n_classes, bias=False)\n",
    "        )\n",
    "#         torch.nn.init.xavier_normal_(self.mlp.weight)\n",
    "            \n",
    "    def forward(self, x, features_only=False):\n",
    "        if features_only:\n",
    "            return self.mlp[:-1](self.backbone(x, features_only=True).detach()) \n",
    "        return self.mlp(self.backbone(x, features_only=True).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_2.ResNet18(\n",
    "    num_classes=64,  \n",
    "    no_fc_layer=True\n",
    ")\n",
    "\n",
    "checkpoint = '../train_dir/classical_miniimagenet_dc_bn_with_var_ortho_scale_test/classical_resnet_217.pt'\n",
    "print(f\"loading from {checkpoint}\")\n",
    "model_dict = model.state_dict()\n",
    "chkpt_state_dict = torch.load(checkpoint)\n",
    "if 'model' in chkpt_state_dict:\n",
    "    chkpt_state_dict = chkpt_state_dict['model']\n",
    "chkpt_state_dict_cpy = chkpt_state_dict.copy()\n",
    "# remove \"module.\" from key, possibly present as it was dumped by data-parallel\n",
    "for key in chkpt_state_dict_cpy.keys():\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "chkpt_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(chkpt_state_dict)\n",
    "updated_keys = set(model_dict).intersection(set(chkpt_state_dict))\n",
    "print(f\"Updated {len(updated_keys)} keys using chkpt\")\n",
    "print(\"Following keys updated :\", \"\\n\".join(sorted(updated_keys)))\n",
    "missed_keys = set(model_dict).difference(set(chkpt_state_dict))\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed :\", \"\\n\".join(sorted(missed_keys)))\n",
    "model.load_state_dict(model_dict)\n",
    "        \n",
    "projector = Projector(model, dim, low_dim, n_classes)\n",
    "projector = torch.nn.DataParallel(projector, device_ids=range(torch.cuda.device_count()))\n",
    "projector.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "classical_val_datamgr = ClassicalDataManager(image_size, batch_size=32)\n",
    "classical_val_loader = classical_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "loss_layer = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(projector.module.mlp.parameters(), lr=0.001)\n",
    "lambda_epoch = lambda e: 1.0 if e < 50  else 0.1\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda_epoch, last_epoch=-1)\n",
    "    \n",
    "for epoch in range(1000):\n",
    "    avg_loss = []\n",
    "    avg_accu = []\n",
    "    iterator = enumerate(classical_val_loader)\n",
    "    for i, batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        batch_x, batch_y = batch\n",
    "        batch_x = batch_x.cuda()\n",
    "        batch_y = batch_y.cuda()\n",
    "        batch_y = batch_y - label_offset\n",
    "        logits = projector(batch_x)\n",
    "        loss = loss_layer(logits, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss.append(loss.item())\n",
    "        avg_accu.append(accuracy(logits, batch_y) * 100.)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"epoch: {epoch} iter: {i} loss : {np.mean(avg_loss)}, accuracy: {np.mean(avg_accu)}\")\n",
    "        if epoch % 5 == 0:\n",
    "            with open(f\"models/projector_{epoch}.pt\", 'wb') as f:\n",
    "                torch.save(projector.state_dict(), f)\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = val_features_dc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PCA() \n",
    "z = pc.fit(A).components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pc.transform(A)) @ z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm = SVM(\n",
    "#     model=model_dc,\n",
    "#     inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "#     n_way=5,\n",
    "#     n_shot=5,\n",
    "#     n_query=15,\n",
    "#     C_reg=1.0,\n",
    "#     device='cuda'\n",
    "# )\n",
    "\n",
    "algorithm = Finetune(\n",
    "    model=model_dc,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_updates=500,\n",
    "    classifier_type='distance-classifier',\n",
    "    final_feat_dim=model_dc.module.final_feat_dim,\n",
    "    n_way=5,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "adaptation_trainer = Generic_adaptation_trainer(\n",
    "    algorithm=algorithm,\n",
    "    aux_objective=None,\n",
    "    outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    outer_optimizer=None, \n",
    "    writer=None,\n",
    "    log_interval=1, grad_clip=0.,\n",
    "    model_type='resnet',\n",
    "    n_aux_objective_steps=0,\n",
    "    label_offset=0)\n",
    "\n",
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=1, n_episodes=50,\n",
    "    n_way=5, n_shot=5, n_query=15)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "adaptation_trainer.run(meta_val_loader, meta_val_datamgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(y_batch, n_way, n_shot, n_query, batch_sz):\n",
    "    # original y_batch: (batch_sz*n_way, n_shot+n_query)\n",
    "    y_batch = y_batch.reshape(batch_sz, n_way, -1)\n",
    "    # batch_sz, n_way, n_shot+n_query\n",
    "\n",
    "    for i in range(y_batch.shape[0]):\n",
    "        uniq_classes = np.unique(y_batch[i, :, :])\n",
    "        conversion_dict = {v:k for k, v in enumerate(uniq_classes)}\n",
    "        # convert labels\n",
    "        for uniq_class in uniq_classes: \n",
    "            y_batch[i, y_batch[i]==uniq_class] = conversion_dict[uniq_class]\n",
    "\n",
    "    shots_y = y_batch[:, :, :n_shot]\n",
    "    query_y = y_batch[:, :, n_shot:]\n",
    "    shots_y = shots_y.reshape(batch_sz, -1)\n",
    "    query_y = query_y.reshape(batch_sz, -1)\n",
    "    return shots_y, query_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=10, n_episodes=50,\n",
    "    n_way=5, n_shot=5, n_query=15)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "it = iter(meta_val_loader)\n",
    "batch_sz=10\n",
    "n_way=5\n",
    "n_shot=5\n",
    "n_query=15\n",
    "x_batch, y_batch = next(it)\n",
    "original_shape = x_batch.shape\n",
    "# (batch_sz*n_way, n_shot+n_query, channels , height , width)\n",
    "x_batch = x_batch.reshape(batch_sz, n_way, *original_shape[-4:])\n",
    "# (batch_sz, n_way, n_shot+n_query, channels , height , width)\n",
    "shots_x = x_batch[:, :, :n_shot, :, :, :]\n",
    "# (batch_sz, n_way, n_shot, channels , height , width)\n",
    "query_x = x_batch[:, :, n_shot:, :, :, :]\n",
    "# (batch_sz, n_way, n_query, channels , height , width)\n",
    "shots_x = shots_x.reshape(batch_sz, -1, *original_shape[-3:])\n",
    "# (batch_sz, n_way*n_shot, channels , height , width)\n",
    "query_x = query_x.reshape(batch_sz, -1, *original_shape[-3:])\n",
    "shots_y, query_y = get_labels(y_batch, n_way, n_shot, n_query, batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "sup_x = shots_x[0]\n",
    "sup_y = shots_y[0]\n",
    "quer_x = query_x[0]\n",
    "quer_y = query_y[0]\n",
    "feat_xs = model_dc(sup_x , features_only=True)\n",
    "feat_xq = model_dc(quer_x , features_only=True)\n",
    "feat_xs = feat_xs / (torch.norm(feat_xs, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "feat_xq = feat_xq / (torch.norm(feat_xq, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, metric='cosine')\n",
    "knn_classifier.fit(feat_xs.detach().cpu().numpy(), sup_y.cpu().numpy())\n",
    "sum(knn_classifier.predict(feat_xq.detach().cpu().numpy()) == quer_y.cpu().numpy()) / len(quer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.svd(feat_x)[2].t()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    sup_x = shots_x[j]\n",
    "    sup_y = shots_y[j]\n",
    "    quer_x = query_x[j]\n",
    "    quer_y = query_y[j]\n",
    "    ll = torch.nn.Linear(512, 16)\n",
    "    ll = ll.cuda()\n",
    "    loss_layer = torch.nn.CrossEntropyLoss()\n",
    "    saved_state_dict = model_dc.state_dict()\n",
    "    opt = torch.optim.Adam([\n",
    "#         {'params': model_dc.parameters(), 'lr': 0.0001},\n",
    "        {'params': ll.parameters(), 'lr': 0.001},\n",
    "    ]) \n",
    "    \n",
    "    sup_x = sup_x.cuda()\n",
    "    sup_y = sup_y.cuda()\n",
    "        \n",
    "    feat_x = model_dc(sup_x , features_only=True)\n",
    "    feat_x = feat_x / (torch.norm(feat_x, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "    feat_x = feat_x.detach()\n",
    "        \n",
    "#     torch.svd(feat_x)[2][]\n",
    "    \n",
    "    for k in range(250):\n",
    "        opt.zero_grad() \n",
    "        loss = loss_layer(ll(feat_x), sup_y) + 0.1 * torch.sum(ll.weight ** 2)\n",
    "        loss.backward()\n",
    "        opt.step()   \n",
    "#     print(f\"loss: {loss.item()}\")\n",
    "    quer_x = quer_x.cuda()\n",
    "    quer_y = quer_y.cuda() \n",
    "    feat_x = model_dc(quer_x , features_only=True)\n",
    "    feat_x = feat_x / (torch.norm(feat_x, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "    quer_logits = ll(feat_x)\n",
    "    model_dc.load_state_dict(saved_state_dict)\n",
    "    print(accuracy(quer_logits, quer_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(72 + 66 + 77 + 65 + 65 + 80 + 70 + 77 + 70 + 61)/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(14/15 + 13/15 + 11/15 + 12/15 + 10/15) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(((np.linalg.svd(S[ys==0])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "# print(np.sum(((np.linalg.svd(S[ys==1])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "# print(np.sum(((np.linalg.svd(S[ys==3])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "# print(np.sum(((np.linalg.svd(S[ys==4])[2][:5] @ Q[yq==0].T).T)**2, axis=1))\n",
    "np.argmax(np.concatenate([\n",
    "    np.sum(((np.linalg.svd(S[ys==0])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==1])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==2])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==3])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :],\n",
    "    np.sum(((np.linalg.svd(S[ys==4])[2][:5] @ Q[yq==3].T).T)**2, axis=1)[None, :]\n",
    "], axis=0).T, axis=1)\n",
    "# print(np.sum((PCA().fit(S[ys==1]).transform(Q[yq==0]))**2, axis=1))\n",
    "# print(np.sum((PCA().fit(S[ys==2]).transform(Q[yq==0]))**2, axis=1))\n",
    "# print(np.sum((PCA().fit(S[ys==3]).transform(Q[yq==0]))**2, axis=1))\n",
    "# print(np.sum((PCA().fit(S[ys==4]).transform(Q[yq==0]))**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_x = shots_x[1]\n",
    "sup_y = shots_y[1]\n",
    "quer_x = query_x[1]\n",
    "quer_y = query_y[1]\n",
    "feat_xs = model_dc(sup_x , features_only=True)\n",
    "feat_xq = model_dc(quer_x , features_only=True)\n",
    "feat_xs = feat_xs / (torch.norm(feat_xs, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "feat_xq = feat_xq / (torch.norm(feat_xq, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "S = feat_xs.detach().cpu().numpy()\n",
    "Q = feat_xq.detach().cpu().numpy()\n",
    "ys = sup_y.cpu().numpy()\n",
    "yq = quer_y.cpu().numpy()\n",
    "np.linalg.svd(np.concatenate([S[ys==0][:1, :], S[ys==1][:1, :], S[ys==2][:1, :], S[ys==3][:1, :], S[ys==4][:1, :]], axis=0))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = PCA(2).fit_transform(feat_x[sup_y==0].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "# arr = PCA(2).fit_transform(feat_x[sup_y==1].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "# arr = PCA(2).fit_transform(feat_x[sup_y==2].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "# arr = PCA(2).fit_transform(feat_x[sup_y==3].detach().cpu().numpy())\n",
    "# plt.scatter(arr[:, 0], arr[:, 1])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "pca_model = PCA(3)\n",
    "\n",
    "sup_x = shots_x[6]\n",
    "sup_y = shots_y[6]\n",
    "quer_x = query_x[6]\n",
    "quer_y = query_y[6]\n",
    "feat_xs = model_dc(sup_x , features_only=True)\n",
    "feat_xq = model_dc(quer_x , features_only=True)\n",
    "feat_xs = feat_xs / (torch.norm(feat_xs, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "feat_xq = feat_xq / (torch.norm(feat_xq, dim=1, p=2, keepdim=True) + 0.0001)\n",
    "\n",
    "arr = pca_model.fit_transform(feat_xs.detach().cpu().numpy())\n",
    "arr2 = pca_model.transform(feat_xq.detach().cpu().numpy())\n",
    "ys = sup_y.cpu().numpy()\n",
    "yq = quer_y.cpu().numpy()\n",
    "# ax.scatter(arr[ys==0, 0], arr[ys==0, 1], arr[ys==0, 2])\n",
    "ax.scatter(arr2[yq==0, 0], arr2[yq==0, 1], arr2[yq==0, 2])\n",
    "# ax.scatter(arr[ys==1, 0], arr[ys==1, 1], arr[ys==1, 2])\n",
    "ax.scatter(arr2[yq==2, 0], arr2[yq==2, 1], arr2[yq==2, 2])\n",
    "ax.scatter(arr2[yq==3, 0], arr2[yq==3, 1], arr2[yq==3, 2])\n",
    "ax.scatter(arr2[yq==4, 0], arr2[yq==4, 1], arr2[yq==4, 2])\n",
    "ax.scatter(arr2[yq==1, 0], arr2[yq==1, 1], arr2[yq==1, 2])\n",
    "# ax.scatter(arr[ys==1, 0], arr[ys==1, 1], arr[ys==1, 2])\n",
    "# ax.scatter(arr[ys==2, 0], arr[ys==2, 1], arr[ys==2, 2])\n",
    "# ax.scatter(arr[ys==4, 0], arr[ys==4, 1], arr[ys==4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projector.module.scale = 1.0\n",
    "algorithm = SVM(\n",
    "    model=projector,\n",
    "    inner_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    n_way=5,\n",
    "    n_shot=5,\n",
    "    n_query=15,\n",
    "    device='cuda',\n",
    ")\n",
    "\n",
    "\n",
    "adaptation_trainer = Generic_adaptation_trainer(\n",
    "    algorithm=algorithm,\n",
    "    aux_objective=None,\n",
    "    outer_loss_func=torch.nn.CrossEntropyLoss(),\n",
    "    outer_optimizer=None, \n",
    "    writer=None,\n",
    "    log_interval=10, grad_clip=0.,\n",
    "    model_type='resnet',\n",
    "    n_aux_objective_steps=0,\n",
    "    label_offset=0)\n",
    "\n",
    "image_size = 224\n",
    "dataset_path = '../data/filelists/miniImagenet'\n",
    "val_file = os.path.join(dataset_path, 'val.json')\n",
    "meta_val_datamgr = MetaDataManager(\n",
    "    image_size, batch_size=5, n_episodes=50,\n",
    "    n_way=5, n_shot=5, n_query=15)\n",
    "meta_val_loader = meta_val_datamgr.get_data_loader(val_file, aug=False)\n",
    "adaptation_trainer.run(meta_val_loader, meta_val_datamgr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
