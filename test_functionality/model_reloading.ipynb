{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models import resnet_12\n",
    "import re\n",
    "from src.optimizers import modified_sgd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chkpt = torch.load('./runs/metal_tiered_r12_SVM_n5s15q6tb8_SGD0.1Drop204050/chkpt_055.pt',\n",
    "#                    map_location=torch.device(\"cuda\"))\n",
    "chkpt = torch.load('../runs/tiered_PN_try/chkpt_055.pt',\n",
    "                   map_location=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['model', 'optimizer'])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "chkpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unit norm projection is  False\nAverage pooling:  False\n"
     ]
    }
   ],
   "source": [
    "model = resnet_12.resnet12(avg_pool=False, drop_rate=0.1, dropblock_size=2,\n",
    "                num_classes=0, classifier_type='no-classifier',\n",
    "                projection=False, learnable_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = modified_sgd.SGD([\n",
    "    {'params': model.parameters(), 'lr': 0.1,\n",
    "    'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': True},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated 100 keys using chkpt\nFollowing keys updated:\nlayer1.0.bn1.bias\nlayer1.0.bn1.num_batches_tracked\nlayer1.0.bn1.running_mean\nlayer1.0.bn1.running_var\nlayer1.0.bn1.weight\nlayer1.0.bn2.bias\nlayer1.0.bn2.num_batches_tracked\nlayer1.0.bn2.running_mean\nlayer1.0.bn2.running_var\nlayer1.0.bn2.weight\nlayer1.0.bn3.bias\nlayer1.0.bn3.num_batches_tracked\nlayer1.0.bn3.running_mean\nlayer1.0.bn3.running_var\nlayer1.0.bn3.weight\nlayer1.0.conv1.weight\nlayer1.0.conv2.weight\nlayer1.0.conv3.weight\nlayer1.0.downsample.0.weight\nlayer1.0.downsample.1.bias\nlayer1.0.downsample.1.num_batches_tracked\nlayer1.0.downsample.1.running_mean\nlayer1.0.downsample.1.running_var\nlayer1.0.downsample.1.weight\nlayer1.0.num_batches_tracked\nlayer2.0.bn1.bias\nlayer2.0.bn1.num_batches_tracked\nlayer2.0.bn1.running_mean\nlayer2.0.bn1.running_var\nlayer2.0.bn1.weight\nlayer2.0.bn2.bias\nlayer2.0.bn2.num_batches_tracked\nlayer2.0.bn2.running_mean\nlayer2.0.bn2.running_var\nlayer2.0.bn2.weight\nlayer2.0.bn3.bias\nlayer2.0.bn3.num_batches_tracked\nlayer2.0.bn3.running_mean\nlayer2.0.bn3.running_var\nlayer2.0.bn3.weight\nlayer2.0.conv1.weight\nlayer2.0.conv2.weight\nlayer2.0.conv3.weight\nlayer2.0.downsample.0.weight\nlayer2.0.downsample.1.bias\nlayer2.0.downsample.1.num_batches_tracked\nlayer2.0.downsample.1.running_mean\nlayer2.0.downsample.1.running_var\nlayer2.0.downsample.1.weight\nlayer2.0.num_batches_tracked\nlayer3.0.bn1.bias\nlayer3.0.bn1.num_batches_tracked\nlayer3.0.bn1.running_mean\nlayer3.0.bn1.running_var\nlayer3.0.bn1.weight\nlayer3.0.bn2.bias\nlayer3.0.bn2.num_batches_tracked\nlayer3.0.bn2.running_mean\nlayer3.0.bn2.running_var\nlayer3.0.bn2.weight\nlayer3.0.bn3.bias\nlayer3.0.bn3.num_batches_tracked\nlayer3.0.bn3.running_mean\nlayer3.0.bn3.running_var\nlayer3.0.bn3.weight\nlayer3.0.conv1.weight\nlayer3.0.conv2.weight\nlayer3.0.conv3.weight\nlayer3.0.downsample.0.weight\nlayer3.0.downsample.1.bias\nlayer3.0.downsample.1.num_batches_tracked\nlayer3.0.downsample.1.running_mean\nlayer3.0.downsample.1.running_var\nlayer3.0.downsample.1.weight\nlayer3.0.num_batches_tracked\nlayer4.0.bn1.bias\nlayer4.0.bn1.num_batches_tracked\nlayer4.0.bn1.running_mean\nlayer4.0.bn1.running_var\nlayer4.0.bn1.weight\nlayer4.0.bn2.bias\nlayer4.0.bn2.num_batches_tracked\nlayer4.0.bn2.running_mean\nlayer4.0.bn2.running_var\nlayer4.0.bn2.weight\nlayer4.0.bn3.bias\nlayer4.0.bn3.num_batches_tracked\nlayer4.0.bn3.running_mean\nlayer4.0.bn3.running_var\nlayer4.0.bn3.weight\nlayer4.0.conv1.weight\nlayer4.0.conv2.weight\nlayer4.0.conv3.weight\nlayer4.0.downsample.0.weight\nlayer4.0.downsample.1.bias\nlayer4.0.downsample.1.num_batches_tracked\nlayer4.0.downsample.1.running_mean\nlayer4.0.downsample.1.running_var\nlayer4.0.downsample.1.weight\nlayer4.0.num_batches_tracked\n\nMissed 1 keys\nFollowing keys missed: scale\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model_dict = model.state_dict() # new model's state dict\n",
    "chkpt_state_dict = chkpt['model']\n",
    "chkpt_state_dict_old_keys = list(chkpt_state_dict.keys())\n",
    "for key in chkpt_state_dict_old_keys:\n",
    "    if 'module.' in key:\n",
    "        new_key = re.sub('module\\.', '',  key)\n",
    "        chkpt_state_dict[new_key] = chkpt_state_dict.pop(key)\n",
    "load_model_state_dict = {k: v for k, v in chkpt_state_dict.items() if k in model_dict}\n",
    "model_dict.update(load_model_state_dict)\n",
    "\n",
    "print(f\"Updated {len(load_model_state_dict.keys())} keys using chkpt\")\n",
    "print(\"Following keys updated:\")\n",
    "print(\"\\n\".join(sorted(load_model_state_dict.keys())))\n",
    "missed_keys = set(model_dict).difference(set(load_model_state_dict))\n",
    "\n",
    "print()\n",
    "print(f\"Missed {len(missed_keys)} keys\")\n",
    "print(\"Following keys missed:\", \"\\n\".join(sorted(missed_keys)))\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.7346e-03, -2.0156e-03, -2.3180e-03],\n",
       "          [-1.7368e-03, -1.7394e-03, -1.7171e-03],\n",
       "          [-1.8053e-03, -1.5829e-03, -1.2368e-03]],\n",
       "\n",
       "         [[ 1.9253e-03,  6.6621e-04,  8.0381e-04],\n",
       "          [ 1.3739e-03,  3.6057e-05,  6.8232e-04],\n",
       "          [ 1.2967e-03,  6.4752e-04,  1.1699e-03]],\n",
       "\n",
       "         [[ 4.7446e-03,  3.0351e-03,  3.2015e-03],\n",
       "          [ 3.9372e-03,  2.0797e-03,  2.7595e-03],\n",
       "          [ 3.6650e-03,  2.4927e-03,  2.9630e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.5395e-04,  6.2875e-03,  9.1429e-03],\n",
       "          [-9.6274e-04,  3.6382e-02,  2.9371e-02],\n",
       "          [ 1.6544e-02, -7.4395e-02, -1.6821e-02]],\n",
       "\n",
       "         [[-4.7016e-03,  6.1646e-03,  7.6912e-03],\n",
       "          [ 1.9596e-03,  5.7076e-02,  3.2797e-02],\n",
       "          [ 3.5127e-02, -9.8689e-02, -2.8160e-02]],\n",
       "\n",
       "         [[-7.3366e-03,  1.7887e-02,  1.6063e-02],\n",
       "          [ 4.8400e-03,  3.1805e-02,  2.0513e-02],\n",
       "          [ 1.3667e-02, -5.4773e-02, -3.2032e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.1392e-03, -2.6531e-03, -2.2012e-03],\n",
       "          [ 6.0575e-03, -1.4777e-03, -1.6910e-03],\n",
       "          [-4.1217e-03, -4.4637e-03, -3.2400e-03]],\n",
       "\n",
       "         [[ 6.6778e-03, -1.5375e-03, -4.0798e-04],\n",
       "          [ 6.0444e-03,  3.6525e-04, -8.7262e-05],\n",
       "          [-8.5312e-04, -1.2084e-03, -6.4652e-04]],\n",
       "\n",
       "         [[ 4.1048e-03, -1.8050e-03, -6.6618e-04],\n",
       "          [ 4.4443e-03, -3.3054e-05, -4.3329e-04],\n",
       "          [-2.2201e-03, -1.6394e-03, -1.0258e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 7.4011e-06, -1.4387e-05, -9.6787e-06],\n",
       "          [ 7.1207e-06, -1.9962e-05, -1.2846e-05],\n",
       "          [ 2.5642e-05, -2.8286e-07,  3.9484e-06]],\n",
       "\n",
       "         [[ 4.7941e-05,  2.5304e-05,  2.2147e-05],\n",
       "          [ 6.0779e-05,  4.6802e-05,  3.8178e-05],\n",
       "          [ 6.8560e-05,  6.2504e-05,  5.1127e-05]],\n",
       "\n",
       "         [[ 3.9366e-05,  4.2464e-05,  2.9763e-05],\n",
       "          [ 6.3314e-05,  6.5826e-05,  5.1204e-05],\n",
       "          [ 7.0523e-05,  7.3346e-05,  5.9129e-05]]],\n",
       "\n",
       "\n",
       "        [[[-8.5497e-04,  3.0898e-04, -2.0924e-04],\n",
       "          [ 3.0142e-04,  1.2693e-03,  4.4780e-04],\n",
       "          [-8.6169e-04,  1.5946e-04, -1.3435e-04]],\n",
       "\n",
       "         [[ 8.5479e-04,  2.4061e-03,  1.5850e-03],\n",
       "          [ 1.9967e-03,  3.4662e-03,  2.4000e-03],\n",
       "          [ 6.5627e-04,  1.6765e-03,  1.1150e-03]],\n",
       "\n",
       "         [[-7.2622e-04,  1.3626e-04, -3.7675e-04],\n",
       "          [ 5.2256e-04,  9.4908e-04,  6.1168e-04],\n",
       "          [-5.4070e-05,  1.9983e-04, -1.5051e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 7.9710e-03, -8.9499e-04,  1.0168e-02],\n",
       "          [ 9.7835e-03,  1.8932e-03,  1.5008e-03],\n",
       "          [ 1.3057e-02, -5.8260e-04,  5.8106e-03]],\n",
       "\n",
       "         [[ 2.7411e-03,  8.5201e-03,  5.8078e-03],\n",
       "          [ 8.2247e-03,  3.7294e-02,  4.7792e-03],\n",
       "          [ 1.2365e-02,  1.4149e-02,  8.9521e-03]],\n",
       "\n",
       "         [[-2.5952e-02,  3.6132e-03, -1.8465e-02],\n",
       "          [-1.1618e-02,  6.6565e-02,  9.7811e-05],\n",
       "          [-2.4875e-02, -5.2294e-04, -1.7535e-02]]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt['model']['layer1.0.conv1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.module.layer1[0].conv1.weight.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs:  0,1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (DropBlock): DropBlock()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "        (conv1): Conv2d(64, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (DropBlock): DropBlock()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "        (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (DropBlock): DropBlock()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (relu): LeakyReLU(negative_slope=0.1)\n",
       "        (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (DropBlock): DropBlock()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n",
    "print('Using GPUs: ', os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['params'][0].is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140600999949648\n",
      "140600999949648\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0]['params'][0].__hash__())\n",
    "print(id(optimizer.param_groups[0]['params'][0])) # torch.nn.parameter.Parameter are a subclass of torch.Tensor, which returns id() for hash values\n",
    "# so two different torch.Tensors despite having the same content will not hash to the same location if they are in different addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.state = chkpt['optimizer'].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0]['params'][0] in optimizer.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(chkpt['optimizer'].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0]['params'][0] in optimizer.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "for key in optimizer.state.keys():\n",
    "    print(optimizer.state[key]['exp_avg'].get_device())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(optimizer.state[key]['exp_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in optimizer.state.keys():\n",
    "#     if key == optimizer.param_groups[0]['params'][0]:\n",
    "#         print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140600999949648\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999842592\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999842752\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999842352\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999842912\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999844992\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999870368\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999869568\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999869168\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999869008\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999843792\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999844352\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999843552\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999890688\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999890048\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999889968\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999828208\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999828048\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999828448\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140601033407056\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140601033406816\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140601033407296\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999867488\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999867088\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999866928\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999887888\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999887648\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999887088\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999889328\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999910848\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999910688\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999910368\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999909568\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999909408\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999889008\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999889168\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999888768\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999926352\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999925952\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999925792\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999925072\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999924832\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999924272\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999923792\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999926512\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999927552\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999907568\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999908928\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "140600999909968\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for key in optimizer.state:\n",
    "    print(key.__hash__())\n",
    "    print(type(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0]['params'][0] in optimizer.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]],\n",
      "\n",
      "\n",
      "        [[[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]],\n",
      "\n",
      "         [[True, True, True],\n",
      "          [True, True, True],\n",
      "          [True, True, True]]]])\n"
     ]
    }
   ],
   "source": [
    "for key in chkpt['optimizer'].state:\n",
    "    if key.shape == model.layer1[0].conv1.weight.shape:\n",
    "        print(key == model.layer1[0].conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chkpt['model'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.scale\n",
      "module.layer1.0.num_batches_tracked\n",
      "module.layer1.0.conv1.weight\n",
      "module.layer1.0.bn1.weight\n",
      "module.layer1.0.bn1.bias\n",
      "module.layer1.0.bn1.running_mean\n",
      "module.layer1.0.bn1.running_var\n",
      "module.layer1.0.bn1.num_batches_tracked\n",
      "module.layer1.0.conv2.weight\n",
      "module.layer1.0.bn2.weight\n",
      "module.layer1.0.bn2.bias\n",
      "module.layer1.0.bn2.running_mean\n",
      "module.layer1.0.bn2.running_var\n",
      "module.layer1.0.bn2.num_batches_tracked\n",
      "module.layer1.0.conv3.weight\n",
      "module.layer1.0.bn3.weight\n",
      "module.layer1.0.bn3.bias\n",
      "module.layer1.0.bn3.running_mean\n",
      "module.layer1.0.bn3.running_var\n",
      "module.layer1.0.bn3.num_batches_tracked\n",
      "module.layer1.0.downsample.0.weight\n",
      "module.layer1.0.downsample.1.weight\n",
      "module.layer1.0.downsample.1.bias\n",
      "module.layer1.0.downsample.1.running_mean\n",
      "module.layer1.0.downsample.1.running_var\n",
      "module.layer1.0.downsample.1.num_batches_tracked\n",
      "module.layer2.0.num_batches_tracked\n",
      "module.layer2.0.conv1.weight\n",
      "module.layer2.0.bn1.weight\n",
      "module.layer2.0.bn1.bias\n",
      "module.layer2.0.bn1.running_mean\n",
      "module.layer2.0.bn1.running_var\n",
      "module.layer2.0.bn1.num_batches_tracked\n",
      "module.layer2.0.conv2.weight\n",
      "module.layer2.0.bn2.weight\n",
      "module.layer2.0.bn2.bias\n",
      "module.layer2.0.bn2.running_mean\n",
      "module.layer2.0.bn2.running_var\n",
      "module.layer2.0.bn2.num_batches_tracked\n",
      "module.layer2.0.conv3.weight\n",
      "module.layer2.0.bn3.weight\n",
      "module.layer2.0.bn3.bias\n",
      "module.layer2.0.bn3.running_mean\n",
      "module.layer2.0.bn3.running_var\n",
      "module.layer2.0.bn3.num_batches_tracked\n",
      "module.layer2.0.downsample.0.weight\n",
      "module.layer2.0.downsample.1.weight\n",
      "module.layer2.0.downsample.1.bias\n",
      "module.layer2.0.downsample.1.running_mean\n",
      "module.layer2.0.downsample.1.running_var\n",
      "module.layer2.0.downsample.1.num_batches_tracked\n",
      "module.layer3.0.num_batches_tracked\n",
      "module.layer3.0.conv1.weight\n",
      "module.layer3.0.bn1.weight\n",
      "module.layer3.0.bn1.bias\n",
      "module.layer3.0.bn1.running_mean\n",
      "module.layer3.0.bn1.running_var\n",
      "module.layer3.0.bn1.num_batches_tracked\n",
      "module.layer3.0.conv2.weight\n",
      "module.layer3.0.bn2.weight\n",
      "module.layer3.0.bn2.bias\n",
      "module.layer3.0.bn2.running_mean\n",
      "module.layer3.0.bn2.running_var\n",
      "module.layer3.0.bn2.num_batches_tracked\n",
      "module.layer3.0.conv3.weight\n",
      "module.layer3.0.bn3.weight\n",
      "module.layer3.0.bn3.bias\n",
      "module.layer3.0.bn3.running_mean\n",
      "module.layer3.0.bn3.running_var\n",
      "module.layer3.0.bn3.num_batches_tracked\n",
      "module.layer3.0.downsample.0.weight\n",
      "module.layer3.0.downsample.1.weight\n",
      "module.layer3.0.downsample.1.bias\n",
      "module.layer3.0.downsample.1.running_mean\n",
      "module.layer3.0.downsample.1.running_var\n",
      "module.layer3.0.downsample.1.num_batches_tracked\n",
      "module.layer4.0.num_batches_tracked\n",
      "module.layer4.0.conv1.weight\n",
      "module.layer4.0.bn1.weight\n",
      "module.layer4.0.bn1.bias\n",
      "module.layer4.0.bn1.running_mean\n",
      "module.layer4.0.bn1.running_var\n",
      "module.layer4.0.bn1.num_batches_tracked\n",
      "module.layer4.0.conv2.weight\n",
      "module.layer4.0.bn2.weight\n",
      "module.layer4.0.bn2.bias\n",
      "module.layer4.0.bn2.running_mean\n",
      "module.layer4.0.bn2.running_var\n",
      "module.layer4.0.bn2.num_batches_tracked\n",
      "module.layer4.0.conv3.weight\n",
      "module.layer4.0.bn3.weight\n",
      "module.layer4.0.bn3.bias\n",
      "module.layer4.0.bn3.running_mean\n",
      "module.layer4.0.bn3.running_var\n",
      "module.layer4.0.bn3.num_batches_tracked\n",
      "module.layer4.0.downsample.0.weight\n",
      "module.layer4.0.downsample.1.weight\n",
      "module.layer4.0.downsample.1.bias\n",
      "module.layer4.0.downsample.1.running_mean\n",
      "module.layer4.0.downsample.1.running_var\n",
      "module.layer4.0.downsample.1.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "for key in chkpt['model'].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(542000, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt['model']['module.layer2.0.num_batches_tracked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(chkpt['optimizer'].state.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chkpt['optimizer'].state.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 3, 1, 1])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([160, 64, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([160, 160, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([160, 160, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([160, 64, 1, 1])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([320, 160, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 320, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([320, 160, 1, 1])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([640, 320, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 640, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 320, 1, 1])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "for key in chkpt['optimizer'].state.keys():\n",
    "    print(key.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt['optimizer'].state[chkpt['model']['module.layer1.0.conv1.weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt['model']['module.layer1.0.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "for key in chkpt['optimizer'].state.keys():\n",
    "    print(type(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in chkpt['optimizer'].state.keys():\n",
    "    try:\n",
    "        if key.shape == torch.Size([64, 3, 3, 3]) and type(key) == torch.Tensor:\n",
    "    #         print(key == chkpt['model']['module.layer1.0.conv1.weight'])\n",
    "            print(chkpt['optimizer'].state[key])\n",
    "    except:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.7346e-03, -2.0156e-03, -2.3180e-03],\n",
       "          [-1.7368e-03, -1.7394e-03, -1.7171e-03],\n",
       "          [-1.8053e-03, -1.5829e-03, -1.2368e-03]],\n",
       "\n",
       "         [[ 1.9253e-03,  6.6621e-04,  8.0381e-04],\n",
       "          [ 1.3739e-03,  3.6057e-05,  6.8232e-04],\n",
       "          [ 1.2967e-03,  6.4752e-04,  1.1699e-03]],\n",
       "\n",
       "         [[ 4.7446e-03,  3.0351e-03,  3.2015e-03],\n",
       "          [ 3.9372e-03,  2.0797e-03,  2.7595e-03],\n",
       "          [ 3.6650e-03,  2.4927e-03,  2.9630e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 6.5395e-04,  6.2875e-03,  9.1429e-03],\n",
       "          [-9.6274e-04,  3.6382e-02,  2.9371e-02],\n",
       "          [ 1.6544e-02, -7.4395e-02, -1.6821e-02]],\n",
       "\n",
       "         [[-4.7016e-03,  6.1646e-03,  7.6912e-03],\n",
       "          [ 1.9596e-03,  5.7076e-02,  3.2797e-02],\n",
       "          [ 3.5127e-02, -9.8689e-02, -2.8160e-02]],\n",
       "\n",
       "         [[-7.3366e-03,  1.7887e-02,  1.6063e-02],\n",
       "          [ 4.8400e-03,  3.1805e-02,  2.0513e-02],\n",
       "          [ 1.3667e-02, -5.4773e-02, -3.2032e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 8.1392e-03, -2.6531e-03, -2.2012e-03],\n",
       "          [ 6.0575e-03, -1.4777e-03, -1.6910e-03],\n",
       "          [-4.1217e-03, -4.4637e-03, -3.2400e-03]],\n",
       "\n",
       "         [[ 6.6778e-03, -1.5375e-03, -4.0798e-04],\n",
       "          [ 6.0444e-03,  3.6525e-04, -8.7262e-05],\n",
       "          [-8.5312e-04, -1.2084e-03, -6.4652e-04]],\n",
       "\n",
       "         [[ 4.1048e-03, -1.8050e-03, -6.6618e-04],\n",
       "          [ 4.4443e-03, -3.3054e-05, -4.3329e-04],\n",
       "          [-2.2201e-03, -1.6394e-03, -1.0258e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 7.4011e-06, -1.4387e-05, -9.6787e-06],\n",
       "          [ 7.1207e-06, -1.9962e-05, -1.2846e-05],\n",
       "          [ 2.5642e-05, -2.8286e-07,  3.9484e-06]],\n",
       "\n",
       "         [[ 4.7941e-05,  2.5304e-05,  2.2147e-05],\n",
       "          [ 6.0779e-05,  4.6802e-05,  3.8178e-05],\n",
       "          [ 6.8560e-05,  6.2504e-05,  5.1127e-05]],\n",
       "\n",
       "         [[ 3.9366e-05,  4.2464e-05,  2.9763e-05],\n",
       "          [ 6.3314e-05,  6.5826e-05,  5.1204e-05],\n",
       "          [ 7.0523e-05,  7.3346e-05,  5.9129e-05]]],\n",
       "\n",
       "\n",
       "        [[[-8.5497e-04,  3.0898e-04, -2.0924e-04],\n",
       "          [ 3.0142e-04,  1.2693e-03,  4.4780e-04],\n",
       "          [-8.6169e-04,  1.5946e-04, -1.3435e-04]],\n",
       "\n",
       "         [[ 8.5479e-04,  2.4061e-03,  1.5850e-03],\n",
       "          [ 1.9967e-03,  3.4662e-03,  2.4000e-03],\n",
       "          [ 6.5627e-04,  1.6765e-03,  1.1150e-03]],\n",
       "\n",
       "         [[-7.2622e-04,  1.3626e-04, -3.7675e-04],\n",
       "          [ 5.2256e-04,  9.4908e-04,  6.1168e-04],\n",
       "          [-5.4070e-05,  1.9983e-04, -1.5051e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 7.9710e-03, -8.9499e-04,  1.0168e-02],\n",
       "          [ 9.7835e-03,  1.8932e-03,  1.5008e-03],\n",
       "          [ 1.3057e-02, -5.8260e-04,  5.8106e-03]],\n",
       "\n",
       "         [[ 2.7411e-03,  8.5201e-03,  5.8078e-03],\n",
       "          [ 8.2247e-03,  3.7294e-02,  4.7792e-03],\n",
       "          [ 1.2365e-02,  1.4149e-02,  8.9521e-03]],\n",
       "\n",
       "         [[-2.5952e-02,  3.6132e-03, -1.8465e-02],\n",
       "          [-1.1618e-02,  6.6565e-02,  9.7811e-05],\n",
       "          [-2.4875e-02, -5.2294e-04, -1.7535e-02]]]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkpt['model']['module.layer1.0.conv1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd0d0b689fbde6198cf17cc6cba3cafe0a89d3e1d92f85638547a96ca00660631c2",
   "display_name": "Python 3.7.6 64-bit ('py37': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}